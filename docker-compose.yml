version: '3'
services:
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-webserver
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/usr/local/etl-pipeline/airflow/dags 
      - AIRFLOW__WEBSERVER__SECRET_KEY=my$e(ret%ey2103
      - PYTHONPATH=/usr/local/etl-pipeline
      - CLIENT_ID=${CLIENT_ID}
      - CLIENT_SECRET=${CLIENT_SECRET}
      - REDIRECT_URI=${REDIRECT_URI}
      - ACCESS_TOKEN=${ACCESS_TOKEN}
      - REFRESH_TOKEN=${REFRESH_TOKEN}
      - USER_ID=${USER_ID}
    volumes:
      - ./:/usr/local/etl-pipeline
      - ./logs:/usr/local/airflow/logs
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    command:
      - webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-scheduler
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/usr/local/etl-pipeline/airflow/dags 
      - AIRFLOW__SCHEDULER__SECRET_KEY=my$e(ret%ey2103
      - PYTHONPATH=/usr/local/etl-pipeline
      - CLIENT_ID=${CLIENT_ID}
      - CLIENT_SECRET=${CLIENT_SECRET}
      - REDIRECT_URI=${REDIRECT_URI}
      - ACCESS_TOKEN=${ACCESS_TOKEN}
      - REFRESH_TOKEN=${REFRESH_TOKEN}
      - USER_ID=${USER_ID}
    volumes:
      - ./:/usr/local/etl-pipeline
      - ./logs:/usr/local/airflow/logs
    depends_on:
      - airflow-webserver
    command:
      - scheduler

volumes:
  pg_data: